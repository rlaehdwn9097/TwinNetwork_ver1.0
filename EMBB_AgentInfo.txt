유저가 요청 횟수 
요청이 많은 시간대 고려 안함
라운드 사이의 간격은 랜덤함
따라서 라운드를 통해서 요일을 계산하고 해당 요일에 요청이 많은 컨테츠를 학습하여 BS 미리 해당 컨텐츠를 캐싱하는 것을 목표
에이전트가 임의의 컨텐츠를 캐싱하는 게 액션

state 는 모든 BS 어떤 컨텐츠들이 저장되어 있는 지와 각 노드에 가용할 수 있는 사이즈가 남아있는 지 등등 차차 생각
policy 는 생각.
액션 정의


요청이 왔을 때 캐싱이 됐으면 상관없고
없으면 백본 네트워크에 가서 가져와야한다 
이거를 저장하는게 좋을지 아닐지 
용량이 꽉차면 Gain 함수로 이득이 없는 컨텐츠 지움


데이터 요청시 해당 데이터가 캐싱이 되어있지 않으면 백본에 가서 데이터를 들고 와야함
해당 데이터를 저장할지 말지


BackBone : internet

Data Center : 정보 전산원
              1개             

Base Station : 제도관 
               9개

Micro Base Station : Base Station 한단계 밑
                     100개

Node : 유저
       300개

###-----------------------------------------------------------<eMBB>-----------------------------------------------------------###
MDP 가 성립이 되는 문제인가?

각각의 input 이 독립적인가? 

한 노드마다 하나의 에이전트가 아닌 모든 노드를 하나의 에이전트에 넣어도 되는가?

state는 어떻게 정의할 것인가?

agent 는 어떤 action을 하는가?
cache gain  공식은 DQN 이랑 무관하게 저장할지 말지




<컨텐츠의 카테고리>
총 3가지
- 코미디 (예능 포함임)
- 뉴스 (뉴스, 다큐멘터리)
- 드라마 


<AgentInfo>
- state : { 현재 {Data Center, Base Station, Micro Base Station}에 캐싱이 되어있는 카테고리별 컨텐츠,
            ...
}

- action : { 요청받은 데이터를 어느 storage 에 저장하느나.
             랜덤 노드에 저장해서 reward 를 저장 
             
             그러면 
} 

- reward : {

    Reward = a*(d_core - d_cache) - b*(R_cache/H_arg)

    d_core  : 네트워크 코어에서 해당 컨텐츠를 전송 받을 경우에 예상되는 지연 시간.
    d_cache : 가장 가까운 레벨의 캐시 서버에서 해당 컨텐츠를 받아올 때 걸리는 실제 소요 시간
    R_cache : 네트워크에 존재하는 동일한 캐시의 수
    H_arg   : 동일한 캐시 사이의 평균 홉 수 (캐시의 분산도를 나타냄)


}

- policy : {

            

}

- discount_factor : {


}